{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MLRun Projects and GIT\n",
    "  --------------------------------------------------------------------\n",
    "\n",
    "Loading or creating a full project with multiple functions and workflow and working wit Git.\n",
    "\n",
    "#### **notebook how-to's**\n",
    "* Load a project with multiple functions from Git\n",
    "* Run automated workflows (using KubeFlow)\n",
    "* Update, maintain and debug code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "#### **steps**\n",
    "**[Load project from Git or Archive](#load-project)**<br>\n",
    "**[Run a pipeline workflow](#run-pipeline)**<br>\n",
    "**[Updating the project and code](#update-project)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import load_project, code_to_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-project'></a>\n",
    "## Load project from Git or Archive\n",
    "\n",
    "Projects can be stored in a Git repo or in a tar archive (on object store like S3, V3IO).\n",
    "\n",
    "`load_project(context, url)` will load/clone the project to the local context dir and build the project object from the `project.yaml` file in the git/archive root directory. \n",
    "\n",
    "> Note: If URL is not specified it will use the context and search for Git repo inside it, or use the `init_git=True` flag to initialize a Git repo in the target context directory.\n",
    "\n",
    "You can also clone the code into a dir using a CLI commands:\n",
    "\n",
    "`mlrun project my-proj/ -u git://github.com/mlrun/demo-xgb-project.git`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source Git Repo, YOU SHOULD fork this to your account and use the fork\n",
    "url = 'git://github.com/<YOUR-REPO>/demo-xgb-project.git'\n",
    "\n",
    "# alternatively can use tar files, e.g.\n",
    "#url = 'v3io:///users/admin/tars/src-project.tar.gz'\n",
    "\n",
    "project_dir = './'  # change if you want to clone into a different dir\n",
    "proj = load_project(project_dir, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir into the project dir if you are not running from it\n",
    "!cd {project_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'git://github.com/yaronha/demo-xgb-project.git#refs/heads/master'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the project object, note it contains lists of `functions` and `workflows` which will be used in the project. Functions can be local to the project or referenced to (via a URL to .ipynb, .py, .yaml file and/or container image). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: iris\n",
      "functions:\n",
      "- url: ./src/iris.yaml\n",
      "  name: xgb\n",
      "- url: https://raw.githubusercontent.com/mlrun/functions/master/serving/xgboost/xgb_serving.ipynb\n",
      "  name: serving\n",
      "workflows:\n",
      "  main: src/workflow.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(proj.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-02-24 11:28:54,880 function spec saved to path: src/iris.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f8282ab8780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can update the function .py and .yaml from a notebook (code + spec)\n",
    "# the \"code_output\" option will generate a .py file from our notebook which can be used for src control and local runs\n",
    "xgbfn = code_to_function('xgb', filename='notebooks/train-xgboost.ipynb' ,kind='job', code_output='src/iris.py')\n",
    "xgbfn.export('src/iris.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: job\n",
      "metadata:\n",
      "  name: xgb\n",
      "  tag: ''\n",
      "  hash: d2664f418144eeb02b0205d379ddfe8269de6829\n",
      "  project: iris\n",
      "spec:\n",
      "  command: src/iris.py\n",
      "  args: []\n",
      "  image: ''\n",
      "  volumes: []\n",
      "  volume_mounts: []\n",
      "  env: []\n",
      "  description: ''\n",
      "  build:\n",
      "    source: git://github.com/yaronha/demo-xgb-project.git#refs/heads/master\n",
      "    base_image: mlrun/mlrun\n",
      "    commands:\n",
      "    - pip install sklearn\n",
      "    - pip install xgboost\n",
      "    - pip install matplotlib\n",
      "    code_origin: https://github.com/yaronha/demo-xgb-project.git#391138bbaffe829906950ea5329a3221f7052cf5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read specific function spec\n",
    "print(proj.func('xgb').to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='update-project'></a>\n",
    "## Updating the project and code\n",
    "\n",
    "A user can update the code using the standard Git process (commit, push, ..), if you update/edit the project object you need to run `proj.save()` which will update the `project.yaml` file in your context directory, followed by pushing your updates.\n",
    "\n",
    "You can use `proj.push(branch, commit_message, add=[])` which will do the work for you (save the yaml, commit updates, push)\n",
    "\n",
    "> Note: you must push updates before you build functions or run workflows since the builder will pull the code from the git repo.\n",
    "\n",
    "If you are using containerized Jupyter you may need to first set your Git parameters, e.g.:\n",
    "\n",
    "```\n",
    "!git config --global user.email \"<my@email.com>\"\n",
    "!git config --global user.name \"<name>\"\n",
    "!git config --global credential.helper store\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.push('master', 'some edits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to pull changes done by others use `proj.pull()`, if you need to update the project spec (since the yaml file changed) use `proj.reload()` and for updating the local/remote function specs use `proj.sync_functions()` (or add `sync=True` to `.reload()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='run-pipeline'></a>\n",
    "## Run a pipeline workflow\n",
    "You can check the [workflow.py](src/workflow.py) file to see how functions objects are initialized and used (by name) inside the workflow.\n",
    "The `workflow.py` file has two parts, initialize the function objects and define pipeline dsl (connect the function inputs and outputs).\n",
    "\n",
    "> Note the pipeline can include CI steps like building container images and deploying models.\n",
    "\n",
    "### Initializing the functions (e.g. mount them on the v3io fabric)\n",
    "```python\n",
    "def init_functions(functions: dict, params=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "```\n",
    "<br>\n",
    "\n",
    "### Workflow DSL:\n",
    "```python\n",
    "@dsl.pipeline(\n",
    "    name='My XGBoost training pipeline',\n",
    "    description='Shows how to use mlrun.'\n",
    ")\n",
    "def kfpipeline(\n",
    "        eta=[0.1, 0.2, 0.3], gamma=[0.1, 0.2, 0.3]\n",
    "):\n",
    "    # first step build the function container\n",
    "    builder = funcs['xgb'].deploy_step(with_mlrun=False)\n",
    "\n",
    "    # use xgb.iris_generator function to generate data (container image from the builder)\n",
    "    ingest = funcs['xgb'].as_step(name='ingest_iris', handler='iris_generator',\n",
    "        image=builder.outputs['image'],\n",
    "        outputs=['iris_dataset'])\n",
    "\n",
    "    # use xgb.xgb_train function to train on the data (from the generator step)\n",
    "    train = funcs['xgb'].as_step(name='xgb_train', handler='xgb_train',\n",
    "        image=builder.outputs['image'],\n",
    "        hyperparams={'eta': eta, 'gamma': gamma},\n",
    "        selector='max.accuracy',\n",
    "        inputs={'dataset': ingest.outputs['iris_dataset']},\n",
    "        outputs=['model'])\n",
    "\n",
    "    # deploy the trained model using a nuclio real-time function\n",
    "    deploy = funcs['serving'].deploy_step(models={'iris_v1': train.outputs['model']})\n",
    "```\n",
    "\n",
    "### Run\n",
    "use the `run` method to execute a workflow, you can provide alternative arguments and specify the default target for workflow artifacts.<br>\n",
    "The workflow ID is returned and can be used to track the progress or you can use the hyperlinks\n",
    "\n",
    "> Note: The same command can be issued through CLI commands:<br>\n",
    "    `mlrun project my-proj/ -r main -p \"v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/\"`\n",
    "\n",
    "The dirty flag allow us to run a project with uncommited changes (when the notebook is in the same git dir it will always be dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-02-24 11:32:38,407 WARNING!, you seem to have uncommitted git changes, use .push()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/jupyter/lib/python3.6/site-packages/kfp/components/_data_passing.py:133: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[0.1, 0.2, 0.3]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd2.com/pipelines/#/experiments/details/4f76db7f-7514-47e5-aab2-afee0558afce\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.yh41.iguazio-cd2.com/pipelines/#/runs/details/5714ab89-331f-45a1-9ca5-b7949ee8f98e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-02-24 11:32:38,526 Pipeline run id=5714ab89-331f-45a1-9ca5-b7949ee8f98e, check UI or DB for progress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5714ab89-331f-45a1-9ca5-b7949ee8f98e'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.run('main', arguments={}, artifact_path='v3io:///users/admin/mlrun/kfp/{{workflow.uid}}/', dirty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing the source path to speed debug\n",
    "\n",
    "Instead of updating Git anytime we modify code we can build the code from the shared file system on the cluster (the build container will mount to the same location with the code instead of reading from Git).\n",
    "\n",
    "We need to change the project source to point to the shared file system URL of our context directory (e.g. v3io), and we can re-run the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.source = 'v3io:///users/admin/my-proj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[back to top](#top)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
